{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part2:Simple_Convolutional_Neural_Network_for_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akashsindhu/MNIST/blob/master/part2_Simple_Convolutional_Neural_Network_for_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8RmLAWWOvkK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   The ﬁrst hidden layer is a convolutional layer called a Convolution2D. The layer has 32 feature maps, which with the size of 5×5 and a rectiﬁer activation function. This is the input layer, expecting images with the structure outline above.\n",
        "2. Next we deﬁne a pooling layer that takes the maximum value called MaxPooling2D. It is conﬁgured with a pool size of 2×2. 3. The next layer is a regularization layer using dropout called Dropout. It is conﬁgured to randomly exclude 20% of neurons in the layer in order to reduce overﬁtting.\n",
        "4. Next is a layer that converts the 2D matrix data to a vector called Flatten. It allows the output to be processed by standard fully connected layers.\n",
        "5. Next a fully connected layer with 128 neurons and rectiﬁer activation function is used.\n",
        "6. Finally, the output layer has 10 neurons for the 10 classes and a softmax activation function to output probability-like predictions for each class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7TU-3A6qRAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Flatten \n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofbcs9OfyTkU",
        "colab_type": "code",
        "outputId": "84b71471-8b12-4778-8de6-dd6d439e477a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "# reshape to be [samples][height][width][channels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJpzobod0Sq9",
        "colab_type": "code",
        "outputId": "6351c19a-f7ba-4f33-db89-b224ed5d0c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs, cannot do labelencoding as neural network will give weightage to each class different. We want same weightage to everyone.\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEoMMRDm0a9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if k.image_data_format() == 'channels_first':\n",
        "#     X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "#     X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "#     input_shape = (1, img_rows, img_cols)\n",
        "# else:\n",
        "#     X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
        "#     X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
        "#     input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "# # one hot encoding\n",
        "# y_train = np_utils.to_categorical(y_train)\n",
        "# y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ51JvS20o09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# num_classes = y_test.shape[1]\n",
        "# input_shape = (1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbG2KUgr1Yuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def baseline_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf2qDYwBqhRY",
        "colab_type": "code",
        "outputId": "ac23b9fe-4485-4d0d-de77-694e0e57a9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "loss, accu = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(\"CNN accuracy: %.2f%%\" % (accu*100))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 0.2265 - acc: 0.9350 - val_loss: 0.0746 - val_acc: 0.9771\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.0709 - acc: 0.9784 - val_loss: 0.0476 - val_acc: 0.9841\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0504 - acc: 0.9847 - val_loss: 0.0417 - val_acc: 0.9859\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0397 - acc: 0.9874 - val_loss: 0.0388 - val_acc: 0.9869\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0318 - acc: 0.9903 - val_loss: 0.0354 - val_acc: 0.9884\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0327 - val_acc: 0.9901\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0221 - acc: 0.9930 - val_loss: 0.0346 - val_acc: 0.9892\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0190 - acc: 0.9939 - val_loss: 0.0324 - val_acc: 0.9890\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0301 - val_acc: 0.9898\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0127 - acc: 0.9960 - val_loss: 0.0289 - val_acc: 0.9907\n",
            "CNN accuracy: 99.07%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}